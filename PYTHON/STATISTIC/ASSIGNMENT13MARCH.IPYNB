{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact \n",
    "the validity of the results.\n",
    "\n",
    "    Analysis of variance (ANOVA) is a statistical method used to test for significant differences between two or more groups. It assumes that the data follows certain assumptions, and violations of these assumptions can impact the validity of the results. The three main assumptions required to use ANOVA are:\n",
    "\n",
    "    1.) Independence: The observations in each group must be independent of each other. This means that the response of one participant should not be influenced by the response of another participant.\n",
    "\n",
    "    2.) Normality: The distribution of the response variable within each group should be approximately normal. This means that the mean, median, and mode should be similar and the data should be symmetrically distributed.\n",
    "\n",
    "    3.)Homogeneity of variances: The variance of the response variable should be the same across all groups. This means that the spread of the data should be similar in each group.\n",
    "\n",
    "If these assumptions are violated, the results of the ANOVA test may not be valid or reliable. Here are some examples of violations that could impact the validity of the results:\n",
    "\n",
    "    1.) Violation of independence: If there is dependence between observations, such as in repeated measures designs or matched pairs, this assumption is violated. For example, if the same participant is tested under multiple conditions, their responses may be influenced by previous conditions.\n",
    "\n",
    "    2.) Violation of normality: If the response variable is not normally distributed, this assumption is violated. For example, if the data is heavily skewed or has outliers, the normality assumption may be violated. This can be checked using a normal probability plot or a Shapiro-Wilk test.\n",
    "\n",
    "    3.) Violation of homogeneity of variances: If the variances of the response variable are not equal across groups, this assumption is violated. For example, if the variance in one group is much larger than the others, the homogeneity assumption may be violated. This can be checked using a Levene's test or by comparing boxplots of the data.\n",
    "\n",
    "It is important to check these assumptions before conducting an ANOVA analysis to ensure the validity and reliability of the results. If one or more of the assumptions are violated, alternative statistical methods such as non-parametric tests or data transformation may be necessary."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. What are the three types of ANOVA, and in what situations would each be used?\n",
    "\n",
    "The three types of ANOVA are:\n",
    "\n",
    "    1.) One-way ANOVA: One-way ANOVA is used when there is only one independent variable or factor with three or more levels, and the dependent variable is continuous. For example, a researcher may want to compare the mean test scores of students in three different classes.\n",
    "\n",
    "    2.) Two-way ANOVA: Two-way ANOVA is used when there are two independent variables or factors, and the dependent variable is continuous. For example, a researcher may want to compare the mean test scores of students in different classes and with different teaching methods.\n",
    "\n",
    "    3.) Repeated measures ANOVA: Repeated measures ANOVA is used when the same participants are measured on the same dependent variable at different times or under different conditions. This is also known as within-subjects ANOVA. For example, a researcher may want to compare the mean test scores of students before and after a new teaching method is implemented.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?\n",
    "\n",
    "    The partitioning of variance in ANOVA refers to the process of dividing the total variance in a dataset into different components based on the sources of variation. The total variance in a dataset can be decomposed into three components: the between-group variance, the within-group variance, and the total variance.\n",
    "\n",
    "    The between-group variance measures the differences between the means of the groups being compared, and it is calculated by taking the sum of squares between (SSB). The within-group variance measures the differences within each group, and it is calculated by taking the sum of squares within (SSW). The total variance is the sum of the between-group and within-group variances, and it is calculated by taking the sum of squares total (SST).\n",
    "\n",
    "    Understanding the partitioning of variance is important in ANOVA because it helps us to determine the relative importance of the sources of variation in the data. By examining the ratio of the between-group variance to the within-group variance (i.e., the F-ratio), we can determine whether there are significant differences between the means of the groups being compared. The partitioning of variance also allows us to identify the main effects of different factors, as well as any interactions between factors, which can help us to better understand the relationships between variables in the data.\n",
    "\n",
    "    Additionally, understanding the partitioning of variance is important for interpreting the results of ANOVA and communicating those results to others. By clearly presenting the different components of variance in the data, we can provide a more accurate and nuanced understanding of the relationships between variables and the factors that are driving those relationships."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual \n",
    "sum of squares (SSR) in a one-way ANOVA using Python?\n",
    "\n",
    "    To calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python, you can use the f_oneway() function from the scipy.stats module. This function takes in the data from each group as arguments and returns the F-statistic, p-value, SST, SSE, and SSR.\n",
    "    In this example, we have defined three groups of data, group1, group2, and group3, each with five observations. We then use the f_oneway() function to calculate the F-statistic and p-value for the one-way ANOVA. Finally, we calculate the SST, SSE, and SSR using the formulae SST = sum((x - mean(x))^2), SSE = sum((xi - mean(x))^2), and SSR = SST - SSE, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 0.09090909090909091\n",
      "p-value: 0.9137235050432447\n",
      "SST: 223.33333333333337\n",
      "SSE: 220.0\n",
      "SSR: 3.3333333333333712\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Define the data for each group\n",
    "group1 = [10, 12, 14, 16, 18]\n",
    "group2 = [8, 11, 14, 17, 20]\n",
    "group3 = [9, 12, 15, 18, 21]\n",
    "\n",
    "# Calculate the F-statistic, p-value, and sums of squares\n",
    "f_statistic, p_value = f_oneway(group1, group2, group3)\n",
    "SST = sum((group1 + group2 + group3 - np.mean(group1 + group2 + group3))**2)\n",
    "SSE = sum((group1 - np.mean(group1))**2) + sum((group2 - np.mean(group2))**2) + sum((group3 - np.mean(group3))**2)\n",
    "SSR = SST - SSE\n",
    "\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "print(\"SST:\", SST)\n",
    "print(\"SSE:\", SSE)\n",
    "print(\"SSR:\", SSR)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Generate some example data\n",
    "np.random.seed(123)\n",
    "factor1 = np.random.choice(['A', 'B'], size=100)\n",
    "factor2 = np.random.choice(['X', 'Y', 'Z'], size=100)\n",
    "y = np.random.normal(loc=10, scale=2, size=100)\n",
    "\n",
    "# Combine the data into a pandas dataframe\n",
    "data = pd.DataFrame({'factor1': factor1,\n",
    "                     'factor2': factor2,\n",
    "                     'y': y})\n",
    "\n",
    "# Save the dataframe to a CSV file\n",
    "data.to_csv('data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.866990577862453\n",
      "5.546257603214495\n",
      "0.7005694443023006\n",
      "0.23406125180959103\n",
      "0.7486609604613251\n",
      "0.09456628785818283\n",
      "0.6296538529040898\n",
      "0.4757984973850178\n",
      "0.9098538658990207\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "data = pd.read_csv('data.csv')\n",
    "model = ols('y ~ C(factor1) + C(factor2) + C(factor1):C(factor2)', data=data).fit()\n",
    "print(sm.stats.anova_lm(model, typ=2)['sum_sq']['C(factor1)'])\n",
    "print(sm.stats.anova_lm(model, typ=2)['sum_sq']['C(factor2)'])\n",
    "print(sm.stats.anova_lm(model, typ=2)['sum_sq']['C(factor1):C(factor2)'])\n",
    "\n",
    "print(sm.stats.anova_lm(model, typ=2)['F']['C(factor1)'])\n",
    "print(sm.stats.anova_lm(model, typ=2)['F']['C(factor2)'])\n",
    "print(sm.stats.anova_lm(model, typ=2)['F']['C(factor1):C(factor2)'])\n",
    "\n",
    "print(sm.stats.anova_lm(model, typ=2)['PR(>F)']['C(factor1)'])\n",
    "print(sm.stats.anova_lm(model, typ=2)['PR(>F)']['C(factor2)'])\n",
    "print(sm.stats.anova_lm(model, typ=2)['PR(>F)']['C(factor1):C(factor2)'])\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. \n",
    "What can you conclude about the differences between the groups, and how would you interpret these \n",
    "results?\n",
    "\n",
    "    If you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02, this suggests that there are significant differences between at least two of the groups being compared. The F-statistic of 5.23 represents the ratio of the variability between the groups to the variability within the groups. A higher F-statistic suggests that the differences between the groups are larger relative to the variability within the groups.\n",
    "\n",
    "    The p-value of 0.02 indicates that there is a 2% probability of observing an F-statistic as extreme as 5.23 or higher under the null hypothesis of no difference between the groups. Since the p-value is less than the commonly accepted significance level of 0.05, we reject the null hypothesis and conclude that there are significant differences between at least two of the groups.\n",
    "\n",
    "    It's important to note that the ANOVA only tells us that there are significant differences between the groups; it does not identify which specific groups are different from one another. To determine which groups differ significantly, post-hoc tests such as Tukey's HSD or Bonferroni's correction could be used. Additionally, it is important to consider the practical significance of the differences observed, as statistical significance does not necessarily imply practical significance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential \n",
    "consequences of using different methods to handle missing data?\n",
    "\n",
    "    Handling missing data in a repeated measures ANOVA is an important step to ensure the accuracy and validity of the results. There are different methods to handle missing data, including pairwise deletion, listwise deletion, imputation, and maximum likelihood estimation.\n",
    "\n",
    "    --Pairwise deletion involves including only the available data for each analysis, so each participant with at least one complete observation is included. This method is easy to implement but may lead to a loss of power and biased estimates if the data is not missing completely at random.\n",
    "\n",
    "    --Listwise deletion, also known as complete case analysis, involves excluding all participants who have any missing data. This method is simple and may produce unbiased estimates if data is missing completely at random. However, it may lead to a loss of power and biased estimates if the data is missing not at random.\n",
    "\n",
    "    --Imputation involves replacing missing data with plausible values based on statistical methods, such as mean imputation, regression imputation, or multiple imputation. Imputation methods can increase the precision of the estimates and reduce bias if the imputation model is appropriate. However, imputation can also introduce bias if the imputation model is misspecified, and the uncertainty due to missing data is not fully accounted for.\n",
    "\n",
    "    --Maximum likelihood estimation is another method for handling missing data, which uses all available data to estimate the parameters of the model. This method can be more efficient and robust than imputation methods, but it requires assuming a distributional form for the missing data, which may not be realistic.\n",
    "\n",
    "    //The potential consequences of using different methods to handle missing data in a repeated measures ANOVA can be significant. The choice of method can affect the power of the test, the precision of the estimates, and the validity of the results. Therefore, it is important to carefully consider the nature of the missing data, the assumptions of the analysis, and the potential consequences of different methods before selecting the appropriate approach. It is also recommended to perform sensitivity analyses to assess the robustness of the results to different assumptions about the missing data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide \n",
    "an example of a situation where a post-hoc test might be necessary.\n",
    "\n",
    "    Common post-hoc tests used after ANOVA include the Tukey-Kramer test, the Bonferroni test, the Scheffe test, and the Duncan test. Each test has its own strengths and weaknesses, and the choice of test depends on the specific research question and the characteristics of the data. Here is a brief overview of these post-hoc tests:\n",
    "\n",
    "    1.) Tukey-Kramer test: This test is used to compare all possible pairs of means and control the family-wise error rate. It is appropriate when the sample sizes are equal or unequal and the variances are homogenous or heterogeneous.\n",
    "\n",
    "    2.) Bonferroni test: This test is used to compare all possible pairs of means while controlling the overall type I error rate. It is appropriate when the sample sizes are equal and the variances are homogenous.\n",
    "\n",
    "    3.) Scheffe test: This test is used to compare all possible combinations of means and control the family-wise error rate. It is appropriate when the sample sizes are equal or unequal and the variances are homogenous or heterogeneous.\n",
    "\n",
    "    4.) Duncan test: This test is used to compare all possible pairs of means and is appropriate when the sample sizes are equal and the variances are homogenous.\n",
    "\n",
    "    ////As an example, consider a study that investigates the effects of different treatments on the growth of plants. The study includes four treatment groups, and the researchers want to know if there are any significant differences between the mean growth rates of the groups. After conducting an ANOVA, the researchers find a significant main effect of treatment. To determine which treatment groups differ significantly from each other, they perform a post-hoc test. Depending on the specific characteristics of the data, they might choose to use the Tukey-Kramer, Bonferroni, Scheffe, or Duncan test to compare the means. The results of the post-hoc test will provide information on which treatment groups differ significantly from each other and allow the researchers to make more precise conclusions about the effects of the treatments on plant growth."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from \n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python \n",
    "to determine if there are any significant differences between the mean weight loss of the three diets. \n",
    "Report the F-statistic and p-value, and interpret the results.\n",
    "\n",
    "    We first create a pandas dataframe to store the data, where the diet column indicates the diet group, and the weight_loss column contains the weight loss data. We then use the f_oneway function from the scipy.stats module to conduct a one-way ANOVA and obtain the F-statistic and p-value. Finally, we print the F-statistic and p-value, and interpret the results by checking if the p-value is less than 0.05 (a common significance level). If the p-value is less than 0.05, we conclude that there is a significant difference between the mean weight loss of the three diets; otherwise, we conclude that there is no significant difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 5.13, p-value: 0.0097\n",
      "There is a significant difference between the mean weight loss of the three diets.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# create a pandas dataframe to store the data\n",
    "data = pd.DataFrame({\n",
    "    'diet': ['A']*10 + ['B']*20 + ['C']*20,\n",
    "    'weight_loss': [1.5, 2.0, 3.0, 2.5, 1.8, 2.3, 1.9, 2.6, 2.2, 2.1,\n",
    "                    2.8, 2.4, 2.2, 2.3, 2.6, 2.7, 2.9, 2.1, 1.7, 2.0,\n",
    "                    1.8, 2.2, 2.3, 2.5, 2.0, 2.1, 2.2, 2.5, 2.3, 2.6,\n",
    "                    2.7, 2.4, 2.6, 2.3, 2.5, 2.2, 2.4, 2.1, 2.8, 2.9,\n",
    "                    2.6, 2.7, 2.4, 2.5, 2.8, 2.9, 2.7, 2.5, 2.6, 2.3]\n",
    "})\n",
    "\n",
    "# conduct a one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(\n",
    "    data[data['diet'] == 'A']['weight_loss'],\n",
    "    data[data['diet'] == 'B']['weight_loss'],\n",
    "    data[data['diet'] == 'C']['weight_loss'])\n",
    "\n",
    "# print the F-statistic and p-value\n",
    "print(f'F-statistic: {f_statistic:.2f}, p-value: {p_value:.4f}')\n",
    "\n",
    "# interpret the results\n",
    "if p_value < 0.05:\n",
    "    print('There is a significant difference between the mean weight loss of the three diets.')\n",
    "else:\n",
    "    print('There is no significant difference between the mean weight loss of the three diets.')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10. A company wants to know if there are any significant differences in the average time it takes to \n",
    "complete a task using three different software programs: Program A, Program B, and Program C. They \n",
    "randomly assign 30 employees to one of the programs and record the time it takes each employee to \n",
    "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or \n",
    "interaction effects between the software programs and employee experience level (novice vs. \n",
    "experienced). Report the F-statistics and p-values, and interpret the results.\n",
    "\n",
    "    A two-way ANOVA using Python to analyze the differences in the average time it takes to complete a task using three different software programs and employee experience level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\FSDS\\PYTHON\\STATISTIC\\ASSIGNMENT13MARCH.IPYNB Cell 15\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/FSDS/PYTHON/STATISTIC/ASSIGNMENT13MARCH.IPYNB#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mstatsmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstats\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmulticomp\u001b[39;00m \u001b[39mimport\u001b[39;00m pairwise_tukeyhsd\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/FSDS/PYTHON/STATISTIC/ASSIGNMENT13MARCH.IPYNB#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# create a DataFrame with the data\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/FSDS/PYTHON/STATISTIC/ASSIGNMENT13MARCH.IPYNB#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame({\u001b[39m'\u001b[39;49m\u001b[39mProgram\u001b[39;49m\u001b[39m'\u001b[39;49m: [\u001b[39m'\u001b[39;49m\u001b[39mA\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mA\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mA\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mB\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mB\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mB\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m*\u001b[39;49m \u001b[39m2\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/FSDS/PYTHON/STATISTIC/ASSIGNMENT13MARCH.IPYNB#X21sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                      \u001b[39m'\u001b[39;49m\u001b[39mExperience\u001b[39;49m\u001b[39m'\u001b[39;49m: [\u001b[39m'\u001b[39;49m\u001b[39mNovice\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m*\u001b[39;49m \u001b[39m9\u001b[39;49m \u001b[39m+\u001b[39;49m [\u001b[39m'\u001b[39;49m\u001b[39mExperienced\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m*\u001b[39;49m \u001b[39m9\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/FSDS/PYTHON/STATISTIC/ASSIGNMENT13MARCH.IPYNB#X21sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                      \u001b[39m'\u001b[39;49m\u001b[39mTime\u001b[39;49m\u001b[39m'\u001b[39;49m: [\u001b[39m23\u001b[39;49m, \u001b[39m21\u001b[39;49m, \u001b[39m22\u001b[39;49m, \u001b[39m20\u001b[39;49m, \u001b[39m18\u001b[39;49m, \u001b[39m19\u001b[39;49m, \u001b[39m17\u001b[39;49m, \u001b[39m16\u001b[39;49m, \u001b[39m16\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/FSDS/PYTHON/STATISTIC/ASSIGNMENT13MARCH.IPYNB#X21sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                               \u001b[39m25\u001b[39;49m, \u001b[39m23\u001b[39;49m, \u001b[39m24\u001b[39;49m, \u001b[39m22\u001b[39;49m, \u001b[39m20\u001b[39;49m, \u001b[39m21\u001b[39;49m, \u001b[39m19\u001b[39;49m, \u001b[39m18\u001b[39;49m, \u001b[39m18\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/FSDS/PYTHON/STATISTIC/ASSIGNMENT13MARCH.IPYNB#X21sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                               \u001b[39m29\u001b[39;49m, \u001b[39m27\u001b[39;49m, \u001b[39m28\u001b[39;49m, \u001b[39m26\u001b[39;49m, \u001b[39m24\u001b[39;49m, \u001b[39m25\u001b[39;49m, \u001b[39m23\u001b[39;49m, \u001b[39m22\u001b[39;49m, \u001b[39m22\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/FSDS/PYTHON/STATISTIC/ASSIGNMENT13MARCH.IPYNB#X21sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m                               \u001b[39m27\u001b[39;49m, \u001b[39m25\u001b[39;49m, \u001b[39m26\u001b[39;49m, \u001b[39m24\u001b[39;49m, \u001b[39m22\u001b[39;49m, \u001b[39m23\u001b[39;49m, \u001b[39m21\u001b[39;49m, \u001b[39m20\u001b[39;49m, \u001b[39m20\u001b[39;49m]})\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/FSDS/PYTHON/STATISTIC/ASSIGNMENT13MARCH.IPYNB#X21sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# conduct a two-way ANOVA\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/FSDS/PYTHON/STATISTIC/ASSIGNMENT13MARCH.IPYNB#X21sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m model \u001b[39m=\u001b[39m ols(\u001b[39m'\u001b[39m\u001b[39mTime ~ C(Program) + C(Experience) + C(Program):C(Experience)\u001b[39m\u001b[39m'\u001b[39m, data)\u001b[39m.\u001b[39mfit()\n",
      "File \u001b[1;32mc:\\Users\\DINESHASHUTOSH\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:636\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    630\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[0;32m    631\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[0;32m    632\u001b[0m     )\n\u001b[0;32m    634\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[0;32m    635\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 636\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, typ\u001b[39m=\u001b[39;49mmanager)\n\u001b[0;32m    637\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[0;32m    638\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmrecords\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmrecords\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DINESHASHUTOSH\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\construction.py:502\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    494\u001b[0m     arrays \u001b[39m=\u001b[39m [\n\u001b[0;32m    495\u001b[0m         x\n\u001b[0;32m    496\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(x\u001b[39m.\u001b[39mdtype, ExtensionDtype)\n\u001b[0;32m    497\u001b[0m         \u001b[39melse\u001b[39;00m x\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m    498\u001b[0m         \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m arrays\n\u001b[0;32m    499\u001b[0m     ]\n\u001b[0;32m    500\u001b[0m     \u001b[39m# TODO: can we get rid of the dt64tz special case above?\u001b[39;00m\n\u001b[1;32m--> 502\u001b[0m \u001b[39mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[39m=\u001b[39;49mdtype, typ\u001b[39m=\u001b[39;49mtyp, consolidate\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[1;32mc:\\Users\\DINESHASHUTOSH\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\construction.py:120\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    118\u001b[0m     \u001b[39m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m         index \u001b[39m=\u001b[39m _extract_index(arrays)\n\u001b[0;32m    121\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m         index \u001b[39m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mc:\\Users\\DINESHASHUTOSH\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\construction.py:674\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    672\u001b[0m lengths \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(raw_lengths))\n\u001b[0;32m    673\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(lengths) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 674\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAll arrays must be of the same length\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    676\u001b[0m \u001b[39mif\u001b[39;00m have_dicts:\n\u001b[0;32m    677\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    678\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    679\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# create a DataFrame with the data\n",
    "data = pd.DataFrame({'Program': ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C'] * 2,\n",
    "                     'Experience': ['Novice'] * 9 + ['Experienced'] * 9,\n",
    "                     'Time': [23, 21, 22, 20, 18, 19, 17, 16, 16, \n",
    "                              25, 23, 24, 22, 20, 21, 19, 18, 18,\n",
    "                              29, 27, 28, 26, 24, 25, 23, 22, 22,\n",
    "                              27, 25, 26, 24, 22, 23, 21, 20, 20]})\n",
    "\n",
    "# conduct a two-way ANOVA\n",
    "model = ols('Time ~ C(Program) + C(Experience) + C(Program):C(Experience)', data).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# print the ANOVA table\n",
    "print(anova_table)\n",
    "\n",
    "# perform a post-hoc test\n",
    "posthoc = pairwise_tukeyhsd(data['Time'], data['Program'], alpha=0.05)\n",
    "print(posthoc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                            sum_sq    df         F    PR(>F)\n",
    "C(Program)               239.8000   2.0  9.256881  0.000806\n",
    "C(Experience)             13.8889   1.0  0.678888  0.417863\n",
    "C(Program):C(Experience)  11.1111   2.0  0.429035  0.655660\n",
    "Residual                 481.0000  24.0       NaN       NaN\n",
    "\n",
    "Multiple Comparison of Means - Tukey HSD,FWER=0.05\n",
    "===============================================\n",
    "group1 group2 meandiff lower upper reject\n",
    "-----------------------------------------------\n",
    "  A      B     -2.8889 -7.0362 1.2585 False \n",
    "  A      C     -3.3333 -7.4806 0.8141 False \n",
    "  B      C     -0.4444 -4.5917 3.7029 False \n",
    "-----------------------------------------------\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q11. An educational researcher is interested in whether a new teaching method improves student test \n",
    "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the \n",
    "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a \n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores \n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which \n",
    "group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-sample t-test: t = -3.03, p = 0.003\n",
      "-------------------------------------------------------------------------\n",
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "=========================================================\n",
      " group1    group2    meandiff p-adj  lower  upper  reject\n",
      "---------------------------------------------------------\n",
      "control experimental   4.5336 0.0028 1.5846 7.4826   True\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Generate example data\n",
    "np.random.seed(123)\n",
    "control_scores = np.random.normal(loc=70, scale=10, size=100)\n",
    "experimental_scores = np.random.normal(loc=75, scale=10, size=100)\n",
    "\n",
    "# Combine the data into a pandas dataframe\n",
    "data = pd.DataFrame({'group': ['control']*100 + ['experimental']*100,\n",
    "                     'score': np.concatenate((control_scores, experimental_scores))})\n",
    "\n",
    "# Two-sample t-test\n",
    "control_scores = data[data['group'] == 'control']['score']\n",
    "experimental_scores = data[data['group'] == 'experimental']['score']\n",
    "t_stat, p_val = stats.ttest_ind(control_scores, experimental_scores)\n",
    "print(f'Two-sample t-test: t = {t_stat:.2f}, p = {p_val:.3f}')\n",
    "print(\"-------------------------------------------------------------------------\")\n",
    "\n",
    "# Tukey's HSD test\n",
    "tukey_results = pairwise_tukeyhsd(data['score'], data['group'])\n",
    "print(tukey_results)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q12. A researcher wants to know if there are any significant differences in the average daily sales of three \n",
    "retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store \n",
    "on those days. Conduct a repeated measures ANOVA using Python to determine if there are any \n",
    "significant differences in sales between the three stores. If the results are significant, follow up with a post\u0002hoc test to determine which store(s) differ significantly from each other.\n",
    "\n",
    "    A repeated measures ANOVA is used when we measure the same variable multiple times under different conditions. In this case, we measure the daily sales of three retail stores (Store A, Store B, and Store C) for 30 days. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Anova\n",
      "==================================\n",
      "    F Value  Num DF  Den DF Pr > F\n",
      "----------------------------------\n",
      "day  0.8407 29.0000 58.0000 0.6897\n",
      "==================================\n",
      "\n",
      "-------------------------------------------------------------------------\n",
      " Multiple Comparison of Means - Tukey HSD, FWER=0.05  \n",
      "======================================================\n",
      "group1 group2 meandiff p-adj   lower    upper   reject\n",
      "------------------------------------------------------\n",
      "     A      B  59.6771 0.1214 -11.9246 131.2789  False\n",
      "     A      C  87.6449 0.0123  16.0431 159.2467   True\n",
      "     B      C  27.9678  0.622  -43.634  99.5696  False\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Generate example data\n",
    "np.random.seed(123)\n",
    "store_a_sales = np.random.normal(loc=500, scale=100, size=30)\n",
    "store_b_sales = np.random.normal(loc=550, scale=100, size=30)\n",
    "store_c_sales = np.random.normal(loc=600, scale=100, size=30)\n",
    "\n",
    "# Combine the data into a pandas dataframe\n",
    "data = pd.DataFrame({'day': list(range(1, 31))*3,\n",
    "                     'store': ['A']*30 + ['B']*30 + ['C']*30,\n",
    "                     'sales': np.concatenate((store_a_sales, store_b_sales, store_c_sales))})\n",
    "\n",
    "# Repeated measures ANOVA\n",
    "model = AnovaRM(data, 'sales', 'store', within=['day'])\n",
    "results = model.fit()\n",
    "print(results.summary())\n",
    "print(\"-------------------------------------------------------------------------\")\n",
    "\n",
    "# Tukey's HSD test\n",
    "tukey_results = pairwise_tukeyhsd(data['sales'], data['store'])\n",
    "print(tukey_results)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
