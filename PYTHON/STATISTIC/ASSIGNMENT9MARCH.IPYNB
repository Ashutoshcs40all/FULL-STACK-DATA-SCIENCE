{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with \n",
    "an example.\n",
    "\n",
    "        The Probability Mass Function (PMF) and Probability Density Function (PDF) are two important concepts in probability theory and statistics. Both of them are used to describe the probability distribution of a random variable.\n",
    "\n",
    "    The PMF is used for discrete random variables, while the PDF is used for continuous random variables.\n",
    "\n",
    "    The PMF gives the probability of each possible value of a discrete random variable. For example, consider the random variable X that represents the outcome of rolling a fair six-sided die. The possible values of X are {1, 2, 3, 4, 5, 6}, and the PMF is given by:\n",
    "\n",
    "    P(X=1) = 1/6\n",
    "    P(X=2) = 1/6\n",
    "    P(X=3) = 1/6\n",
    "    P(X=4) = 1/6\n",
    "    P(X=5) = 1/6\n",
    "    P(X=6) = 1/6\n",
    "\n",
    "    The sum of all the probabilities in the PMF must be equal to 1.\n",
    "\n",
    "    The PDF gives the probability density of a continuous random variable at each possible value. For example, consider the random variable Y that represents the height of a person chosen at random from a population. The possible values of Y are all the real numbers between 0 and infinity. The PDF for Y can be represented by a function f(y), such that the probability of Y being between two values a and b is given by the integral of f(y) between a and b:\n",
    "\n",
    "    P(a <= Y <= b) = integral from a to b of f(y) dy\n",
    "\n",
    "    The area under the PDF curve must be equal to 1.\n",
    "    The PMF and PDF are used to describe the probability distribution of a random variable, and their specific use depends on whether the random variable is discrete or continuous."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?\n",
    "\n",
    "    The Cumulative Density Function (CDF) is a function that describes the cumulative probability distribution of a random variable. The CDF gives the probability that the random variable takes a value less than or equal to a given value.\n",
    "\n",
    "    For a discrete random variable, the CDF is the sum of the probabilities of all values less than or equal to a given value. For a continuous random variable, the CDF is the integral of the probability density function (PDF) up to a given value.\n",
    "\n",
    "    For example, consider a random variable X that represents the number of heads obtained when a fair coin is flipped three times. The possible values of X are 0, 1, 2, and 3. The PMF of X is given by:\n",
    "\n",
    "    P(X=0) = 1/8\n",
    "    P(X=1) = 3/8\n",
    "    P(X=2) = 3/8\n",
    "    P(X=3) = 1/8\n",
    "\n",
    "The CDF of X is then given by:\n",
    "    F(x) = P(X<=x)\n",
    "\n",
    "    For x=0, F(0) = P(X<=0) = P(X=0) = 1/8\n",
    "    For x=1, F(1) = P(X<=1) = P(X=0) + P(X=1) = 1/8 + 3/8 = 1/2\n",
    "    For x=2, F(2) = P(X<=2) = P(X=0) + P(X=1) + P(X=2) = 1/8 + 3/8 + 3/8 = 7/8\n",
    "    For x=3, F(3) = P(X<=3) = P(X=0) + P(X=1) + P(X=2) + P(X=3) = 1/8 + 3/8 + 3/8 + 1/8 = 1\n",
    "\n",
    "    The CDF is used for a variety of purposes, such as calculating the probability of a range of values, finding percentiles, and generating random numbers from the distribution. It is also useful in comparing different distributions and determining which distribution provides a better fit to the data. Additionally, it can help in identifying outliers and extreme values in the distribution."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3: What are some examples of situations where the normal distribution might be used as a model? \n",
    "Explain how the parameters of the normal distribution relate to the shape of the distribution.\n",
    "\n",
    "    The normal distribution is a widely used probability distribution in statistics and is often used as a model for many real-world situations. Here are some examples of situations where the normal distribution might be used as a model:\n",
    "\n",
    "    1.) Heights of people in a population\n",
    "    2.) IQ scores\n",
    "    3.) Measurement errors\n",
    "    4.) Test scores\n",
    "    5.) Blood pressure readings\n",
    "    6.) Stock prices\n",
    "    The normal distribution is characterized by two parameters: the mean (μ) and the standard deviation (σ). The mean is the central tendency of the distribution and is where the curve is centered. The standard deviation is a measure of the spread of the distribution and determines how much the data deviates from the mean.\n",
    "\n",
    "    The normal distribution is symmetric, with the highest point of the curve at the mean. The shape of the curve is determined by the standard deviation. If the standard deviation is small, the curve will be narrow, indicating that the data is tightly clustered around the mean. If the standard deviation is large, the curve will be wider, indicating that the data is more spread out.\n",
    "\n",
    "    The normal distribution is a bell-shaped curve, and the probability of any value falling within a certain range can be calculated by integrating the normal distribution over that range. The area under the curve is equal to 1, indicating that the probability of any value falling within the entire range of the distribution is 1.\n",
    "\n",
    "    The normal distribution is important in statistics because many statistical methods assume that the data follows a normal distribution. By using the normal distribution as a model, we can make predictions about the likelihood of certain events occurring and estimate the probabilities of different outcomes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal \n",
    "Distribution. \n",
    "\n",
    "    The normal distribution is a fundamental concept in statistics and has a wide range of applications in many fields, including science, engineering, social sciences, and economics. Here are some of the key reasons why the normal distribution is important:\n",
    "\n",
    "    1.) Many real-world phenomena follow a normal distribution: The normal distribution is often used as a model for many real-world phenomena, such as human height, IQ scores, exam scores, errors in measurement, and stock prices. By using the normal distribution as a model, we can make predictions about the likelihood of certain events occurring and estimate the probabilities of different outcomes.\n",
    "\n",
    "    2.) Central limit theorem: The central limit theorem states that if we have a large enough sample size, the distribution of the sample means will be approximately normal, regardless of the underlying distribution of the data. This property is extremely useful in statistics and allows us to make inferences about population parameters based on sample statistics.\n",
    "\n",
    "    3.) Statistical inference: Many statistical tests and methods assume that the data follows a normal distribution. By using the normal distribution as a model, we can perform hypothesis tests, estimate confidence intervals, and make inferences about population parameters.\n",
    "\n",
    "    4.) Mathematical properties: The normal distribution has many mathematical properties that make it easy to work with. For example, the sum or average of a large number of independent and identically distributed random variables often has a normal distribution.\n",
    "\n",
    "    Examples of real-life situations where the normal distribution is used as a model include:\n",
    "\n",
    "    1.) Human height: The height of adult humans typically follows a normal distribution, with the mean around 5'7\" and a standard deviation of around 2.5 inches.\n",
    "\n",
    "    2.) IQ scores: IQ scores are often modeled using a normal distribution, with a mean of 100 and a standard deviation of 15.\n",
    "\n",
    "    3.) Exam scores: Exam scores in a large class can be modeled using a normal distribution, with the mean representing the average score and the standard deviation representing the spread of scores.\n",
    "\n",
    "    4.) Errors in measurement: Errors in measurement are often modeled using a normal distribution, with the mean representing the true value and the standard deviation representing the precision of the measurement.\n",
    "\n",
    "    5.) Stock prices: The daily changes in stock prices are often modeled using a normal distribution, with the mean representing the expected return and the standard deviation representing the volatility of the stock."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli \n",
    "Distribution and Binomial Distribution?\n",
    "\n",
    "    Bernoulli distribution is a discrete probability distribution that models a single binary trial that has two possible outcomes: success or failure. It is named after Swiss mathematician Jacob Bernoulli, who introduced it in his book \"Ars Conjectandi\" in 1713.\n",
    "\n",
    "    The Bernoulli distribution is characterized by a single parameter p, which represents the probability of success. The probability mass function (PMF) of the Bernoulli distribution is given by:\n",
    "\n",
    "P(X = 1) = p\n",
    "P(X = 0) = 1 - p\n",
    "\n",
    "where X is the random variable that represents the outcome of the binary trial.\n",
    "\n",
    "    An example of a Bernoulli trial is flipping a coin, where success can be defined as getting a head, and failure can be defined as getting a tail. In this case, p would be 0.5, as the probability of getting a head (success) is 0.5, and the probability of getting a tail (failure) is also 0.5.\n",
    "\n",
    "    The Bernoulli distribution is often used as a building block for more complex distributions, such as the binomial distribution.\n",
    "\n",
    "    The key difference between Bernoulli distribution and binomial distribution is that the Bernoulli distribution models a single binary trial, while the binomial distribution models a sequence of independent Bernoulli trials. In other words, the binomial distribution is the sum of n independent and identically distributed Bernoulli trials.\n",
    "\n",
    "    The binomial distribution is characterized by two parameters: n, the number of trials, and p, the probability of success in each trial. The probability mass function (PMF) of the binomial distribution is given by:\n",
    "\n",
    "P(X = k) = (n choose k) * p^k * (1 - p)^(n - k)\n",
    "\n",
    "where X is the random variable that represents the number of successes in n trials.\n",
    "\n",
    "    An example of the binomial distribution is counting the number of heads in 10 coin flips, where success is defined as getting a head, and failure is defined as getting a tail. In this case, n would be 10, and p would be 0.5."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset \n",
    "is normally distributed, what is the probability that a randomly selected observation will be greater \n",
    "than 60? Use the appropriate formula and show your calculations.\n",
    "\n",
    "    To calculate the probability that a randomly selected observation from a normally distributed dataset with mean 50 and standard deviation 10 will be greater than 60, we need to standardize the value using the z-score formula and then use a standard normal distribution table or calculator to find the corresponding probability.\n",
    "The z-score formula is:\n",
    "\n",
    "z = (x - μ) / σ\n",
    "where x is the value we want to standardize, μ is the mean, and σ is the standard deviation.\n",
    "\n",
    "    In this case, x = 60, μ = 50, and σ = 10. Plugging these values into the z-score formula, we get:\n",
    "\n",
    "z = (60 - 50) / 10 = 1\n",
    "\n",
    "    Now, we need to find the probability that a standard normal distribution is greater than 1. Using a standard normal distribution table or calculator, we find that this probability is approximately 0.1587."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15865525393145707\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "z = (60 - 50) / 10 # calculate the z-score\n",
    "\n",
    "p = 1 - norm.cdf(z)  # calculate the probability using the cumulative distribution function (CDF)\n",
    "print(p)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7: Explain uniform Distribution with an example.\n",
    "\n",
    "        The uniform distribution is a continuous probability distribution that models random variables with equally likely outcomes within a given interval. The probability density function (PDF) of a uniform distribution is a constant function over the interval [a, b], and it is zero outside this interval. The uniform distribution is often used to model situations where every outcome within a certain range is equally likely.\n",
    "\n",
    "    An example of a uniform distribution is the roll of a fair six-sided die. In this case, the possible outcomes are 1, 2, 3, 4, 5, and 6, and each outcome is equally likely. The interval [1, 6] represents the range of possible outcomes, and the PDF of the uniform distribution is:\n",
    "\n",
    "f(x) = 1/6, for 1 <= x <= 6\n",
    "f(x) = 0, otherwise\n",
    "\n",
    "    This means that the probability of rolling any particular number is 1/6, and the probability of rolling any number outside the range [1, 6] is zero.\n",
    "\n",
    "    Another example of a uniform distribution is the distribution of arrival times of customers at a store during a certain time period. If the store is open from 9am to 5pm, and customers arrive at random times within this interval, then the arrival times can be modeled using a uniform distribution over the interval [9, 17], where 9 represents 9am and 17 represents 5pm. In this case, any arrival time within this interval is equally likely, and any arrival time outside this interval is impossible."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8: What is the z score? State the importance of the z score.\n",
    "\n",
    "    A z-score, also known as a standard score, is a measure of how many standard deviations an observation or data point is from the mean of a dataset. It is calculated by subtracting the mean from the observed value and dividing the result by the standard deviation:\n",
    "\n",
    "z = (x - μ) / σ\n",
    "\n",
    "where x is the observed value, μ is the mean of the dataset, and σ is the standard deviation of the dataset.\n",
    "\n",
    "    The importance of the z-score lies in its ability to standardize observations from different datasets with different scales and units into a common scale. By transforming the raw data into z-scores, we can compare observations from different datasets or variables and draw conclusions about their relative positions and significance.\n",
    "\n",
    "    The z-score is also used in hypothesis testing and statistical inference, where it is used to calculate p-values and determine the significance of statistical tests. A z-score of greater than 1.96 or less than -1.96, for example, corresponds to a p-value of less than 0.05, which is often used as a threshold for statistical significance.\n",
    "\n",
    "    In addition, z-scores are useful in identifying outliers in a dataset. Observations with z-scores that are more than three standard deviations away from the mean are generally considered outliers and may need to be investigated further to determine whether they represent valid data points or errors.\n",
    "\n",
    "    Overall, the z-score is an important statistical tool that allows us to compare and analyze data from different sources and draw meaningful conclusions about their significance and variability."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem.\n",
    "\n",
    "    The Central Limit Theorem (CLT) is a fundamental concept in statistics that describes the behavior of the means of a large number of independent, identically distributed random variables. The theorem states that as the sample size increases, the distribution of sample means will approach a normal distribution, regardless of the underlying distribution of the individual data points, as long as certain assumptions are met.\n",
    "\n",
    "    The significance of the Central Limit Theorem lies in its broad applicability to a wide range of statistical problems. By showing that the sample means from a variety of distributions follow a normal distribution under certain conditions, the Central Limit Theorem allows us to make statistical inferences and draw conclusions about population means and variances from a representative sample of data.\n",
    "\n",
    "    The Central Limit Theorem is particularly important in hypothesis testing, where it is used to estimate confidence intervals, calculate p-values, and test the significance of statistical tests. It allows us to use the properties of the normal distribution to make inferences about the behavior of large datasets, even when we do not know the exact distribution of the underlying data.\n",
    "\n",
    "    The Central Limit Theorem also has practical implications in fields such as quality control, finance, and engineering, where it is used to model and analyze complex systems with many variables. By providing a framework for analyzing the behavior of means and variances in large datasets, the Central Limit Theorem has become a cornerstone of modern statistics and an essential tool for making data-driven decisions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10: State the assumptions of the Central Limit Theorem.\n",
    "\n",
    "    The Central Limit Theorem (CLT) is a fundamental concept in statistics that describes the behavior of the means of a large number of independent, identically distributed random variables. The theorem states that as the sample size increases, the distribution of sample means will approach a normal distribution, regardless of the underlying distribution of the individual data points, as long as certain assumptions are met. The assumptions of the Central Limit Theorem are as follows:\n",
    "\n",
    "    1.) Independence: The data points in the sample should be independent of each other. In other words, the value of one data point should not be affected by the value of another data point.\n",
    "\n",
    "    2.) Sample size: The sample size should be large enough. A common rule of thumb is that the sample size should be at least 30.\n",
    "\n",
    "    3.) Identical distribution: The data points should be drawn from the same population, with the same mean and variance.\n",
    "\n",
    "    These assumptions are important because they ensure that the sample means are representative of the population means and that the central limit theorem holds. Violating these assumptions may result in biased or inaccurate estimates of the population means, and the normality of the sample distribution may not be guaranteed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
